\contentsline {chapter}{Abstract}{i}{section*.4}%
\contentsline {chapter}{Acknowledgements}{iii}{section*.5}%
\contentsline {chapter}{Table of Contents}{v}{section*.6}%
\contentsline {chapter}{List of Tables}{viii}{section*.7}%
\contentsline {chapter}{List of Figures}{ix}{section*.8}%
\contentsline {chapter}{Nomenclature}{xi}{section*.9}%
\contentsline {chapter}{Chapter 1.{\ \ \ }Introduction}{1}{chapter.1}%
\contentsline {section}{1.1.{\ \ \ }Research Background and Motivation}{1}{section.1.1}%
\contentsline {section}{1.2.{\ \ \ }Problem Statement and Challenges}{2}{section.1.2}%
\contentsline {section}{1.3.{\ \ \ }Research Contributions}{2}{section.1.3}%
\contentsline {section}{1.4.{\ \ \ }Thesis Organization}{3}{section.1.4}%
\contentsline {chapter}{Chapter 2.{\ \ \ }Related Work}{5}{chapter.2}%
\contentsline {section}{2.1.{\ \ \ }Traditional Fake News Detection Methods}{5}{section.2.1}%
\contentsline {subsection}{2.1.1.{\ \ \ }Feature Engineering Approaches}{5}{subsection.2.1.1}%
\contentsline {subsection}{2.1.2.{\ \ \ }Sequential Models}{6}{subsection.2.1.2}%
\contentsline {section}{2.2.{\ \ \ }Deep Learning Approaches}{6}{section.2.2}%
\contentsline {subsection}{2.2.1.{\ \ \ }Transformer-based Models}{6}{subsection.2.2.1}%
\contentsline {subsection}{2.2.2.{\ \ \ }Large Language Models for Fake News Detection}{7}{subsection.2.2.2}%
\contentsline {section}{2.3.{\ \ \ }Graph-based Fake News Detection}{7}{section.2.3}%
\contentsline {subsection}{2.3.1.{\ \ \ }Document-level Graph Classification}{8}{subsection.2.3.1}%
\contentsline {subsection}{2.3.2.{\ \ \ }User Propagation-based Methods}{8}{subsection.2.3.2}%
\contentsline {subsection}{2.3.3.{\ \ \ }Heterogeneous Graph Neural Networks}{9}{subsection.2.3.3}%
\contentsline {section}{2.4.{\ \ \ }Few-Shot Learning in NLP}{9}{section.2.4}%
\contentsline {subsection}{2.4.1.{\ \ \ }Meta-Learning Approaches}{9}{subsection.2.4.1}%
\contentsline {subsection}{2.4.2.{\ \ \ }Contrastive Learning Methods}{10}{subsection.2.4.2}%
\contentsline {section}{2.5.{\ \ \ }Limitations of Existing Methods}{10}{section.2.5}%
\contentsline {chapter}{Chapter 3.{\ \ \ }Background and Preliminaries}{12}{chapter.3}%
\contentsline {section}{3.1.{\ \ \ }Few-Shot Learning Fundamentals}{12}{section.3.1}%
\contentsline {subsection}{3.1.1.{\ \ \ }Problem Formulation}{12}{subsection.3.1.1}%
\contentsline {subsection}{3.1.2.{\ \ \ }Challenges in Few-Shot Learning}{13}{subsection.3.1.2}%
\contentsline {subsection}{3.1.3.{\ \ \ }Few-Shot Learning Strategies}{13}{subsection.3.1.3}%
\contentsline {section}{3.2.{\ \ \ }Graph Neural Networks for Text Classification}{14}{section.3.2}%
\contentsline {subsection}{3.2.1.{\ \ \ }Message Passing Framework}{14}{subsection.3.2.1}%
\contentsline {subsection}{3.2.2.{\ \ \ }Graph Construction for Text}{14}{subsection.3.2.2}%
\contentsline {subsection}{3.2.3.{\ \ \ }Heterogeneous Graph Attention Networks}{15}{subsection.3.2.3}%
\contentsline {section}{3.3.{\ \ \ }Problem Formulation and Notation}{15}{section.3.3}%
\contentsline {subsection}{3.3.1.{\ \ \ }Fake News Detection as Node Classification}{15}{subsection.3.3.1}%
\contentsline {subsection}{3.3.2.{\ \ \ }Few-Shot Learning Configuration}{16}{subsection.3.3.2}%
\contentsline {subsection}{3.3.3.{\ \ \ }Learning Objective}{16}{subsection.3.3.3}%
\contentsline {chapter}{Chapter 4.{\ \ \ }Methodology: GemGNN Framework}{18}{chapter.4}%
\contentsline {section}{4.1.{\ \ \ }Framework Overview}{18}{section.4.1}%
\contentsline {section}{4.2.{\ \ \ }Generative User Interaction Simulation}{18}{section.4.2}%
\contentsline {subsection}{4.2.1.{\ \ \ }LLM-based Interaction Generation}{18}{subsection.4.2.1}%
\contentsline {subsection}{4.2.2.{\ \ \ }Multi-tone Interaction Design}{19}{subsection.4.2.2}%
\contentsline {subsection}{4.2.3.{\ \ \ }Interaction-News Edge Construction}{19}{subsection.4.2.3}%
\contentsline {section}{4.3.{\ \ \ }Test-Isolated KNN Graph Construction}{20}{section.4.3}%
\contentsline {subsection}{4.3.1.{\ \ \ }Test Isolation Strategy and Motivation}{20}{subsection.4.3.1}%
\contentsline {subsection}{4.3.2.{\ \ \ }Mutual KNN for Training Nodes}{20}{subsection.4.3.2}%
\contentsline {subsection}{4.3.3.{\ \ \ }Ensuring Test-Train Connectivity}{20}{subsection.4.3.3}%
\contentsline {section}{4.4.{\ \ \ }Multi-View Graph Construction}{21}{section.4.4}%
\contentsline {subsection}{4.4.1.{\ \ \ }Embedding Dimension Splitting Strategy}{21}{subsection.4.4.1}%
\contentsline {subsection}{4.4.2.{\ \ \ }View-specific Edge Construction}{21}{subsection.4.4.2}%
\contentsline {subsection}{4.4.3.{\ \ \ }Multi-Graph Training Strategy}{21}{subsection.4.4.3}%
\contentsline {section}{4.5.{\ \ \ }Heterogeneous Graph Architecture}{21}{section.4.5}%
\contentsline {subsection}{4.5.1.{\ \ \ }Node Types and Features}{22}{subsection.4.5.1}%
\contentsline {subsection}{4.5.2.{\ \ \ }Edge Types and Relations}{22}{subsection.4.5.2}%
\contentsline {subsection}{4.5.3.{\ \ \ }HAN-based Message Passing and Classification}{22}{subsection.4.5.3}%
\contentsline {section}{4.6.{\ \ \ }Loss Function Design and Training Strategy}{23}{section.4.6}%
\contentsline {subsection}{4.6.1.{\ \ \ }Enhanced Loss Functions for Few-Shot Learning}{23}{subsection.4.6.1}%
\contentsline {subsection}{4.6.2.{\ \ \ }Transductive Learning Framework}{23}{subsection.4.6.2}%
\contentsline {chapter}{Chapter 5.{\ \ \ }Experimental Setup}{25}{chapter.5}%
\contentsline {section}{5.1.{\ \ \ }Datasets and Preprocessing}{25}{section.5.1}%
\contentsline {subsection}{5.1.1.{\ \ \ }FakeNewsNet Datasets}{25}{subsection.5.1.1}%
\contentsline {subsubsection}{{\ \ \ }PolitiFact Dataset}{25}{subsubsection.5.1.1.1}%
\contentsline {subsubsection}{{\ \ \ }GossipCop Dataset}{26}{subsubsection.5.1.1.2}%
\contentsline {subsection}{5.1.2.{\ \ \ }Data Statistics and Characteristics}{26}{subsection.5.1.2}%
\contentsline {subsection}{5.1.3.{\ \ \ }Text Embedding Generation}{26}{subsection.5.1.3}%
\contentsline {section}{5.2.{\ \ \ }Baseline Methods}{27}{section.5.2}%
\contentsline {subsection}{5.2.1.{\ \ \ }Traditional Methods}{27}{subsection.5.2.1}%
\contentsline {subsection}{5.2.2.{\ \ \ }Language Models}{27}{subsection.5.2.2}%
\contentsline {subsection}{5.2.3.{\ \ \ }Large Language Models}{27}{subsection.5.2.3}%
\contentsline {subsection}{5.2.4.{\ \ \ }Graph-based Methods}{28}{subsection.5.2.4}%
\contentsline {section}{5.3.{\ \ \ }Evaluation Methodology}{28}{section.5.3}%
\contentsline {subsection}{5.3.1.{\ \ \ }Few-Shot Evaluation Protocol}{28}{subsection.5.3.1}%
\contentsline {subsection}{5.3.2.{\ \ \ }Performance Metrics}{29}{subsection.5.3.2}%
\contentsline {subsection}{5.3.3.{\ \ \ }Statistical Significance Testing}{29}{subsection.5.3.3}%
\contentsline {section}{5.4.{\ \ \ }Implementation Details}{29}{section.5.4}%
\contentsline {subsection}{5.4.1.{\ \ \ }Hyperparameter Settings}{29}{subsection.5.4.1}%
\contentsline {subsection}{5.4.2.{\ \ \ }Model Architecture Configuration}{30}{subsection.5.4.2}%
\contentsline {subsection}{5.4.3.{\ \ \ }Training Configuration and Hardware Setup}{30}{subsection.5.4.3}%
\contentsline {chapter}{Chapter 6.{\ \ \ }Results and Analysis}{32}{chapter.6}%
\contentsline {section}{6.1.{\ \ \ }Main Results}{32}{section.6.1}%
\contentsline {subsection}{6.1.1.{\ \ \ }Performance on PolitiFact Dataset}{32}{subsection.6.1.1}%
\contentsline {subsection}{6.1.2.{\ \ \ }Performance on GossipCop Dataset}{33}{subsection.6.1.2}%
\contentsline {subsection}{6.1.3.{\ \ \ }Comparison with Baseline Methods}{34}{subsection.6.1.3}%
\contentsline {section}{6.2.{\ \ \ }Ablation Studies}{34}{section.6.2}%
\contentsline {subsection}{6.2.1.{\ \ \ }Component Analysis}{34}{subsection.6.2.1}%
\contentsline {subsection}{6.2.2.{\ \ \ }Impact of Generative User Interactions}{35}{subsection.6.2.2}%
\contentsline {subsection}{6.2.3.{\ \ \ }Different K-shot Settings Analysis}{36}{subsection.6.2.3}%
\contentsline {subsection}{6.2.4.{\ \ \ }Effect of Different Interaction Tones}{36}{subsection.6.2.4}%
\contentsline {section}{6.3.{\ \ \ }Analysis and Discussion}{36}{section.6.3}%
\contentsline {subsection}{6.3.1.{\ \ \ }Why GemGNN Works in Few-Shot Scenarios}{36}{subsection.6.3.1}%
\contentsline {subsection}{6.3.2.{\ \ \ }Graph Construction Strategy Analysis}{37}{subsection.6.3.2}%
\contentsline {subsection}{6.3.3.{\ \ \ }Model Architecture Comparison}{37}{subsection.6.3.3}%
\contentsline {subsection}{6.3.4.{\ \ \ }Computational Efficiency Analysis}{37}{subsection.6.3.4}%
\contentsline {section}{6.4.{\ \ \ }Error Analysis and Limitations}{38}{section.6.4}%
\contentsline {subsection}{6.4.1.{\ \ \ }Failure Cases and Edge Cases}{38}{subsection.6.4.1}%
\contentsline {subsection}{6.4.2.{\ \ \ }Dependency on Embedding Quality}{38}{subsection.6.4.2}%
\contentsline {subsection}{6.4.3.{\ \ \ }Scalability Considerations}{38}{subsection.6.4.3}%
\contentsline {chapter}{Chapter 7.{\ \ \ }Conclusion and Future Work}{39}{chapter.7}%
\contentsline {section}{7.1.{\ \ \ }Summary of Contributions}{39}{section.7.1}%
\contentsline {section}{7.2.{\ \ \ }Key Findings and Insights}{40}{section.7.2}%
\contentsline {section}{7.3.{\ \ \ }Implications for Fake News Detection}{40}{section.7.3}%
\contentsline {section}{7.4.{\ \ \ }Limitations and Challenges}{41}{section.7.4}%
\contentsline {section}{7.5.{\ \ \ }Future Research Directions}{42}{section.7.5}%
